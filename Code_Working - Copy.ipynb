{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "634fc3c0",
   "metadata": {
    "id": "634fc3c0"
   },
   "source": [
    "# Data Generating Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6bb1572",
   "metadata": {
    "id": "d6bb1572"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.stats import norm, t, uniform\n",
    "path = './Simu'\n",
    "name1 = '/SimuData_p50'\n",
    "name2 = '/SimuData_p100'\n",
    "N = 200\n",
    "m = 100\n",
    "T = 180\n",
    "stdv = 0.05\n",
    "theta_w = 0.02\n",
    "stde = 0.05\n",
    "q = 0.95\n",
    "M = 1\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(path, exist_ok=True)\n",
    "os.makedirs(path + name1, exist_ok=True)\n",
    "os.makedirs(path + name2, exist_ok=True)\n",
    "\n",
    "# Case Pc=100\n",
    "rho = uniform.rvs(0.9, 0.1, size=(m, 1))\n",
    "c = np.zeros((N * T, m))\n",
    "\n",
    "for i in range(m):\n",
    "    x = np.zeros((N, T))\n",
    "    x[:, 0] = norm.rvs(0, 1, size=(N,))\n",
    "    for t in range(1, T):\n",
    "        x[:, t] = rho[i] * x[:, t - 1] + norm.rvs(0, 1, size=(N,)) * np.sqrt(1 - rho[i]**2)\n",
    "    r = np.argsort(x, axis=0)\n",
    "    szx = x.shape\n",
    "    x1 = np.zeros(szx)\n",
    "    ridx = np.arange(1, szx[0] + 1)\n",
    "    for k in range(szx[1]):\n",
    "        x1[r[:, k], k] = ridx * 2 / (N + 1) - 1\n",
    "    c[:, i] = x1.flatten()\n",
    "\n",
    "per = np.repeat(np.arange(1, N + 1), T)\n",
    "time = np.tile(np.arange(1, T + 1), N)\n",
    "vt = np.random.normal(0, 1, size=(3, T)) * stdv\n",
    "beta = c[:, :3]\n",
    "betav = np.zeros(N * T)\n",
    "\n",
    "for t in range(T):\n",
    "    ind = (time == t + 1)\n",
    "    betav[ind] = np.dot(beta[ind, :], vt[:, t])\n",
    "\n",
    "y = np.zeros(T)\n",
    "y[0] = np.random.normal(0, 1)\n",
    "for t in range(1, T):\n",
    "    y[t] = q * y[t - 1] + np.random.normal(0, 1) * np.sqrt(1 - q**2)\n",
    "\n",
    "cy = c.copy()\n",
    "for t in range(T):\n",
    "    ind = (time == t + 1)\n",
    "    cy[ind, :] = c[ind, :] * y[t]\n",
    "\n",
    "ep = np.random.standard_t(df=5, size=N * T) * stde\n",
    "\n",
    "# Model 1\n",
    "theta = np.concatenate(([1, 1], np.repeat(0, m - 2), [0, 0, 1], np.repeat(0, m - 3))) * theta_w\n",
    "r1 = np.hstack((c, cy)).dot(theta) + betav + ep\n",
    "rt = np.hstack((c, cy)).dot(theta)\n",
    "\n",
    "# Saving arrays to CSV files\n",
    "pathc = f\"{path}{name2}/c{M}.csv\"\n",
    "np.savetxt(pathc, np.hstack((c, cy)), delimiter=',')\n",
    "\n",
    "pathr = f\"{path}{name2}/r1_{M}.csv\"\n",
    "np.savetxt(pathr, r1, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ed1d2c5",
   "metadata": {
    "id": "8ed1d2c5"
   },
   "outputs": [],
   "source": [
    "# Create directories\n",
    "os.makedirs(os.path.join(path, name2, '/r2'), exist_ok=True)\n",
    "\n",
    "# Model 2\n",
    "theta = np.concatenate(([1, 1], np.repeat(0, m - 2), [0, 0, 1], np.repeat(0, m - 3))) * theta_w\n",
    "z = np.hstack((c, cy))\n",
    "z[:, 0] = c[:, 0]**2 * 2\n",
    "z[:, 1] = c[:, 0] * c[:, 1] * 1.5\n",
    "z[:, m + 2] = np.sign(cy[:, 2]) * 0.6\n",
    "\n",
    "r1 = z.dot(theta) + betav + ep\n",
    "rt = z.dot(theta)\n",
    "\n",
    "# Saving arrays to CSV files\n",
    "pathr = f\"{path}{name2}/r2_{M}.csv\"\n",
    "np.savetxt(pathr, r1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e652b418",
   "metadata": {
    "id": "e652b418"
   },
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c2b470ec",
   "metadata": {
    "id": "c2b470ec"
   },
   "outputs": [],
   "source": [
    "m = 50\n",
    "\n",
    "# Model 1\n",
    "theta = np.concatenate(([1, 1], np.repeat(0, m - 2), [0, 0, 1], np.repeat(0, m - 3))) * theta_w\n",
    "r1 = np.hstack((c[:, :m], cy[:, :m])).dot(theta) + betav + ep\n",
    "rt = np.hstack((c[:, :m], cy[:, :m])).dot(theta)\n",
    "\n",
    "# Saving arrays to CSV files\n",
    "pathc = f\"{path}{name1}/c{M}.csv\"\n",
    "np.savetxt(pathc, np.hstack((c, cy)), delimiter=',')\n",
    "\n",
    "pathr = f\"{path}{name1}/r1_{M}.csv\"\n",
    "np.savetxt(pathr, r1, delimiter=',')\n",
    "\n",
    "\n",
    "os.makedirs(os.path.join(path, name1, '/r2'), exist_ok=True)\n",
    "\n",
    "# Model 2\n",
    "theta = np.concatenate(([1, 1], np.repeat(0, m - 2), [0, 0, 1], np.repeat(0, m - 3))) * theta_w\n",
    "z_model2 = np.hstack((c[:, :m], cy[:, :m]))\n",
    "z_model2[:, 0] = c[:, 0]**2 * 2\n",
    "z_model2[:, 1] = c[:, 0] * c[:, 1] * 1.5\n",
    "z_model2[:, m + 2] = np.sign(cy[:, 2]) * 0.6\n",
    "\n",
    "r1 = z_model2.dot(theta) + betav + ep\n",
    "rt = z_model2.dot(theta)\n",
    "\n",
    "# Saving arrays to CSV files\n",
    "pathr = f\"{path}{name1}/r2_{M}.csv\"\n",
    "np.savetxt(pathr, r1, delimiter=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9465f2e7",
   "metadata": {
    "id": "9465f2e7"
   },
   "source": [
    "# Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce5c0dc7",
   "metadata": {
    "id": "ce5c0dc7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c074dc",
   "metadata": {
    "id": "48c074dc"
   },
   "source": [
    "First define few functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20228b51",
   "metadata": {
    "id": "20228b51"
   },
   "outputs": [],
   "source": [
    "def fw1(x):\n",
    "    # Find the maximum location of a vector\n",
    "    maximum = np.max(x)\n",
    "    p = np.where(x == maximum)[0]\n",
    "    if len(p) > 1:\n",
    "        p = p[0]\n",
    "    return p\n",
    "\n",
    "def pls(X, y, A):\n",
    "    \"\"\"\n",
    "    Partial Least Squares (PLS) regression\n",
    "\n",
    "    Parameters:\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training data.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        Target values.\n",
    "    A : int\n",
    "        Number of components.\n",
    "\n",
    "    Returns:\n",
    "    B : array, shape (n_features, A)\n",
    "        Coefficients for each component.\n",
    "    \"\"\"\n",
    "    s = X.T.dot(y)\n",
    "    R = np.zeros((X.shape[1], A))\n",
    "    TT = np.zeros((X.shape[0], A))\n",
    "    P = np.zeros((X.shape[1], A))\n",
    "    U = np.zeros((X.shape[0], A))\n",
    "    V = np.zeros((X.shape[1], A))\n",
    "    B = np.zeros((X.shape[1], A))\n",
    "    Q = np.zeros((1, A))\n",
    "\n",
    "    for i in range(A):\n",
    "        q = s.T.dot(s)\n",
    "        r = s.dot(q)\n",
    "        t = X.dot(r)\n",
    "        t = t - np.mean(t)\n",
    "        normt = np.sqrt(t.T.dot(t))\n",
    "        t = t / normt\n",
    "        r = r / normt\n",
    "        p = X.T.dot(t)\n",
    "        q = y.T.dot(t)\n",
    "        u = y * q\n",
    "        v = p\n",
    "        if i > 0:\n",
    "            v = v - V[:, :i+1].dot(V[:, :i+1].T.dot(p))\n",
    "            u = u - TT[:, :i+1].dot(TT[:, :i+1].T.dot(u))\n",
    "        v = v / np.sqrt(v.T.dot(v))\n",
    "        s = s - v.dot(v.T.dot(s))\n",
    "\n",
    "        R[:, i] = r\n",
    "        TT[:, i] = t\n",
    "        P[:, i] = p\n",
    "        U[:, i] = u\n",
    "        V[:, i] = v\n",
    "        Q[:, i] = q\n",
    "\n",
    "    for i in range(A - 1):\n",
    "        C = R[:, :i+1].dot(Q[:, :i+1].T)\n",
    "        B[:, i+1] = C[:, 0]\n",
    "\n",
    "    return B\n",
    "\n",
    "def soft_threshodl(groups, nc, w, mu):\n",
    "    \"\"\"\n",
    "    Soft thresholding operator\n",
    "\n",
    "    Parameters:\n",
    "    groups : int\n",
    "        Not used in the function, placeholder for the MATLAB code.\n",
    "    nc : int\n",
    "        Not used in the function, placeholder for the MATLAB code.\n",
    "    w : array-like\n",
    "        Input array.\n",
    "    mu : float\n",
    "        Threshold parameter.\n",
    "\n",
    "    Returns:\n",
    "    val : array-like\n",
    "        Soft thresholded array.\n",
    "    \"\"\"\n",
    "    val = np.sign(w) * np.maximum(np.abs(w) - mu, 0)\n",
    "    return val\n",
    "\n",
    "def lossh(y, yhat, mu):\n",
    "    \"\"\"\n",
    "    Loss function for proximalH\n",
    "\n",
    "    Parameters:\n",
    "    y : array-like\n",
    "        True target values.\n",
    "    yhat : array-like\n",
    "        Predicted values.\n",
    "    mu : float\n",
    "        Threshold parameter.\n",
    "\n",
    "    Returns:\n",
    "    m : float\n",
    "        Loss value.\n",
    "    \"\"\"\n",
    "    r = np.abs(yhat - y)\n",
    "    l = np.zeros(len(r))\n",
    "    ind = (r > mu)\n",
    "    l[ind] = 2 * mu * r[ind] - mu * mu\n",
    "    ind = (r <= mu)\n",
    "    l[ind] = r[ind] * r[ind]\n",
    "    m = np.mean(l)\n",
    "    return m\n",
    "\n",
    "def f_gradh(w, X, y, mu):\n",
    "    \"\"\"\n",
    "    Gradient of the loss function for proximalH\n",
    "\n",
    "    Parameters:\n",
    "    w : array-like\n",
    "        Coefficients.\n",
    "    X : array-like\n",
    "        Training data.\n",
    "    y : array-like\n",
    "        Target values.\n",
    "    mu : float\n",
    "        Threshold parameter.\n",
    "\n",
    "    Returns:\n",
    "    grad : array-like\n",
    "        Gradient.\n",
    "    \"\"\"\n",
    "    r = np.dot(X, w) - y\n",
    "    ind0 = np.where(np.abs(r) <= mu)[0]\n",
    "    ind1 = np.where(r > mu)[0]\n",
    "    indf1 = np.where(r < -mu)[0]\n",
    "    grad = np.dot(X[ind0, :].T, np.dot(X[ind0, :], w) - y[ind0]) + mu * np.dot(X[ind1, :].T, np.ones(len(ind1))) - mu * np.dot(X[indf1, :].T, np.ones(len(indf1)))\n",
    "    return grad\n",
    "\n",
    "def proximalH(groups, nc, xtest, mtrain, ytest, w, X, y, mu, tol, L, l2, func):\n",
    "    \"\"\"\n",
    "    Proximal operator using accelerated proximal gradient descent\n",
    "\n",
    "    Parameters:\n",
    "    groups : int\n",
    "        Not used in the function, placeholder for the MATLAB code.\n",
    "    nc : int\n",
    "        Not used in the function, placeholder for the MATLAB code.\n",
    "    xtest : array-like\n",
    "        Test data.\n",
    "    mtrain : float\n",
    "        Mean of the training target values.\n",
    "    ytest : array-like\n",
    "        Test target values.\n",
    "    w : array-like\n",
    "        Initial guess of the coefficients.\n",
    "    X : array-like\n",
    "        Training data.\n",
    "    y : array-like\n",
    "        Target values.\n",
    "    mu : float\n",
    "        Threshold parameter.\n",
    "    tol : float\n",
    "        Tolerance parameter for convergence.\n",
    "    L : float\n",
    "        Lipschitz constant.\n",
    "    l2 : float\n",
    "        Regularization parameter.\n",
    "    func : function\n",
    "        Soft thresholding function.\n",
    "\n",
    "    Returns:\n",
    "    a : array-like\n",
    "        Final coefficients after proximal gradient descent.\n",
    "    \"\"\"\n",
    "    dim = X.shape[1]\n",
    "    max_iter = 3000\n",
    "    gamma = 1 / L\n",
    "    l1 = l2\n",
    "    v = w.copy()\n",
    "    yhatbig1 = np.dot(xtest, w) + mtrain\n",
    "    r20 = lossh(yhatbig1, ytest, mu)\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        vold = v.copy()\n",
    "        w_perv = w.copy()\n",
    "        w = v - gamma * f_gradh(v, X, y, mu)\n",
    "        mu1 = l1 * gamma\n",
    "        w = func(groups, nc, w, mu1)\n",
    "        v = w + t / (t + 3) * (w - w_perv)\n",
    "\n",
    "        if np.sum((v - vold) ** 2) < (np.sum(vold ** 2) * tol) or np.sum(np.abs(v - vold)) == 0:\n",
    "            break\n",
    "\n",
    "    return v\n",
    "\n",
    "def proximal(groups, nc, XX, XY, tol, L, l2, func):\n",
    "    dim = XX.shape[0]\n",
    "    max_iter = 30000\n",
    "    gamma = 1 / L\n",
    "    l1 = l2\n",
    "    w = np.zeros(dim)\n",
    "    v = w.copy()\n",
    "\n",
    "    for t in range(max_iter):\n",
    "        vold = v.copy()\n",
    "        w_prev = w.copy()\n",
    "        w = v - gamma * f_grad(XX, XY, v)\n",
    "        w = func(groups, nc, w, l1 * gamma)\n",
    "        v = w + t / (t + 3) * (w - w_prev)\n",
    "        if (np.sum(np.power(v - vold, 2)) < (np.sum(np.power(vold, 2)) * tol)) or (np.sum(np.abs(v - vold)) == 0):\n",
    "            break\n",
    "\n",
    "    return v\n",
    "\n",
    "def f_grad(XX, XY, w):\n",
    "    \"\"\"\n",
    "    Gradient of the objective function.\n",
    "\n",
    "    Parameters:\n",
    "    XX (array): Design matrix.\n",
    "    XY (array): Target values.\n",
    "    w (array): Coefficients.\n",
    "\n",
    "    Returns:\n",
    "    grad (array): Gradient.\n",
    "    \"\"\"\n",
    "    grad = np.dot(XX, w) - XY\n",
    "    return grad\n",
    "\n",
    "def soft_threshodr(groups, nc, w, mu):\n",
    "    \"\"\"\n",
    "    Soft thresholding function for ridge regularization.\n",
    "\n",
    "    Parameters:\n",
    "    groups (array): Groups.\n",
    "    nc (int): Number of components.\n",
    "    w (array): Coefficients.\n",
    "    mu (float): Threshold parameter.\n",
    "\n",
    "    Returns:\n",
    "    val (array): Updated coefficients after soft thresholding.\n",
    "    \"\"\"\n",
    "    val = w / (1 + mu)\n",
    "    return val\n",
    "\n",
    "def cut_knots_degree2(x, n, th):\n",
    "    \"\"\"\n",
    "    cut_knots_degree2\n",
    "    \"\"\"\n",
    "    a, b = x.shape\n",
    "    resultfinal = np.zeros((a, b * (n + 1)))\n",
    "\n",
    "    for i in range(b):\n",
    "        xcut = x[:, i]\n",
    "        xcutnona = np.copy(xcut)\n",
    "        xcutnona[np.isnan(xcutnona)] = 0\n",
    "        index = ((1 - 1 * np.isnan(xcut)) == 1)\n",
    "\n",
    "        t = th[:, i]\n",
    "\n",
    "        x1 = xcutnona\n",
    "        resultfinal[:, (n + 1) * i - n] = x1 - np.mean(x1)\n",
    "        x1 = np.power(xcutnona - t[0], 2)\n",
    "        resultfinal[:, (n + 1) * i - n + 1] = x1 - np.mean(x1)\n",
    "\n",
    "        for j in range(n - 1):\n",
    "            x1 = np.power(xcutnona - t[j + 1], 2) * (xcutnona >= t[j + 1])\n",
    "            resultfinal[:, (n + 1) * i - n + 1 + j] = x1 - np.mean(x1)\n",
    "\n",
    "    return resultfinal\n",
    "\n",
    "def soft_threshode(groups, nc, w, mu):\n",
    "    # soft_threshode\n",
    "    val = np.sign(w) * np.maximum(np.abs(w) - 0.5 * mu, 0) / (1 + 0.5 * mu)\n",
    "    return val\n",
    "\n",
    "def soft_threshodg(groups, nc, w, mu):\n",
    "    w1 = np.copy(w)\n",
    "    for i in range(1, nc + 1):\n",
    "        ind = (groups == i)\n",
    "        wg = w1[ind]\n",
    "        nn = len(wg)\n",
    "        n2 = np.sqrt(np.sum(wg ** 2))\n",
    "        if n2 <= mu:\n",
    "            w1[ind] = np.zeros(nn)\n",
    "        else:\n",
    "            w1[ind] = wg - mu * wg / n2\n",
    "    return w1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e093911",
   "metadata": {
    "id": "9e093911"
   },
   "source": [
    "Get to the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96cc1a2d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "96cc1a2d",
    "outputId": "2181dcfd-a554-45e8-d295-f2768ca3e838",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: 0.019\n",
      "Simple OLS+H R2: 0.020\n",
      "PCR R2: 0.008\n",
      "PLS R2: 0.030\n",
      "Enet R2 : 0.04\n",
      "Enet+H R2 : 0.04\n",
      "Group Lasso R2: 0.04\n",
      "Group Lasso+H R2: 0.04\n"
     ]
    }
   ],
   "source": [
    "MC = 1  # setup MC number\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "# hh = [1, 3, 6, 12]  # correspond to monthly, quarterly, half-year, and annually returns\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 180   # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln - 1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PCR\n",
    "        modeln += 1\n",
    "        ne = 30\n",
    "        X = np.dot(xtrain.T, xtrain)\n",
    "        pca_vec = V.T\n",
    "        p1 = pca_vec[:, :ne]\n",
    "        Z = np.dot(xtrain, p1)\n",
    "        r = np.zeros((3, ne))\n",
    "        B = np.zeros((xtrain.shape[1], ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne - 1):\n",
    "            xx = Z[:, :j + 1]\n",
    "            b = np.dot(np.linalg.inv(np.dot(xx.T, xx)), np.dot(xx.T, Y))\n",
    "            b = np.dot(p1[:, :j + 1], b)\n",
    "\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1 - ytest, 2)) / np.sum(np.power(ytest - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "            B[:, j] = b\n",
    "\n",
    "        b = np.zeros(xtest.shape[1])\n",
    "        j = ne - 1\n",
    "        yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "        r[0, j] = 1 - np.sum(np.power(yhatbig1 - ytest, 2)) / np.sum(np.power(ytest - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r[1, j] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r[2, j] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        B[:, j] = b\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln - 1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PCR R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PLS\n",
    "        modeln += 1\n",
    "        B = pls(xtrain, ytrain_demean, 30)\n",
    "        ne = 30\n",
    "        r = np.zeros((3, ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne):\n",
    "            b = B[:, j]\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1 - ytest, 2)) / np.sum(np.power(ytest - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln - 1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "\n",
    "        # Elastic Net\n",
    "        modeln += 1\n",
    "        lamv = np.arange(-2, 4.1, 0.1)\n",
    "        alpha = 0.5\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j in range(len(lamv)):\n",
    "            l2 = 10 ** lamv[j]\n",
    "            func = soft_threshode\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1 - ytest, 2)) / np.sum(np.power(ytest - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        l2 = 10 ** lamv[int(fw1(r[0]))]\n",
    "        func = soft_threshode\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshode\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln-1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln-1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln - 1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet+H R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        # Group Lasso\n",
    "        kn = 4\n",
    "        th = np.zeros((kn, xtrain.shape[1]))\n",
    "        th[1, :] = 0\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            th[:, i] = np.quantile(xtrain[:, i], np.arange(kn) / kn)\n",
    "\n",
    "        xtrain = cut_knots_degree2(xtrain, kn, th)\n",
    "        xtest = cut_knots_degree2(xtest, kn, th)\n",
    "        xoos = cut_knots_degree2(xoos, kn, th)\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] = xtrain[:, i] / s\n",
    "                xtest[:, i] = xtest[:, i] / s\n",
    "                xoos[:, i] = xoos[:, i] / s\n",
    "\n",
    "        Y = ytrain_demean\n",
    "        XX = xtrain.T @ xtrain\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        XY = xtrain.T @ Y\n",
    "\n",
    "        modeln += 1\n",
    "        lamv = np.arange(0.5, 3.1, 0.1)\n",
    "        nc = XX.shape[1] // (kn + 1)\n",
    "        groups = np.repeat(np.arange(1, nc + 1), kn + 1)\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j, lam in enumerate(lamv):\n",
    "            l2 = 10 ** lam\n",
    "            func = soft_threshodg\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = xtest @ b + mtrain\n",
    "            r[0, j] = 1 - np.sum((yhatbig1 - ytest) ** 2) / np.sum((ytest - mtrain) ** 2)\n",
    "            yhatbig1 = xoos @ b + mtrain\n",
    "            r[1, j] = 1 - np.sum((yhatbig1 - yoos) ** 2) / np.sum((yoos - mtrain) ** 2)\n",
    "            yhatbig1 = xtrain @ b + mtrain\n",
    "            r[2, j] = 1 - np.sum((yhatbig1 - ytrain) ** 2) / np.sum((ytrain - mtrain) ** 2)\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, np.int16(fw1(r[0, :]))]\n",
    "        r2_is[modeln - 1] = r[2, np.int16(fw1(r[0, :]))]\n",
    "        l2 = 10 ** lamv[np.int16(fw1(r[0, :]))]\n",
    "\n",
    "        func = soft_threshodg\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln - 1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso R2:\", np.round(r2_oos[modeln - 1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshodg\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = xoos @ b + mtrain\n",
    "        r2_oos[modeln -1] = 1 - np.sum((yhatbig1 - yoos) ** 2) / np.sum((yoos - mtrain) ** 2)\n",
    "        yhatbig1 = xtrain @ b + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum((yhatbig1 - ytrain) ** 2) / np.sum((ytrain - mtrain) ** 2)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln - 1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso+H R2:\", np.round(r2_oos[modeln - 1], 3))\n",
    "\n",
    "        pathr = f\"{title}/roos\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_oos, delimiter=\",\")\n",
    "\n",
    "        pathr = f\"{title}/ris\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_is, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5730f894",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5730f894",
    "outputId": "3e3b9921-2165-4865-d25e-0312ec4405ca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01945444, 0.02013166, 0.00830992, 0.02968415, 0.04022508,\n",
       "       0.04003227, 0.03963787, 0.03969461, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_oos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acd9bd57",
   "metadata": {
    "id": "acd9bd57"
   },
   "outputs": [],
   "source": [
    "output = pd.DataFrame(columns = [\"OLS + H\", \"OLS-3 + H\", \"PCR\", \"PLS\", \"Enet + H\", \"GLM + H\", \"RF\", \"GBRT + H\"], data=np.zeros((3,8)))\n",
    "output.index = [\"All\", \"Top 1000\", \"Bottom 1000\"]\n",
    "output.iloc[0,0] =r2_oos[1]\n",
    "output.iloc[0,2] = r2_oos[2]\n",
    "output.iloc[0,3] = r2_oos[3]\n",
    "output.iloc[0,4] = r2_oos[5]\n",
    "output.iloc[0,5] = r2_oos[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95c876f7",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "95c876f7",
    "outputId": "355f4658-02ff-4a76-cfa0-e2d14ca48899"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"output\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"OLS + H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.011623016633614392,\n        \"min\": 0.0,\n        \"max\": 0.0201316553466383,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          0.0201316553466383\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"OLS-3 + H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PCR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.004797734866471529,\n        \"min\": 0.0,\n        \"max\": 0.00830992054997337,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"PLS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.017138153096324195,\n        \"min\": 0.0,\n        \"max\": 0.029684151910727374,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Enet + H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.023112640406467714,\n        \"min\": 0.0,\n        \"max\": 0.04003226748107147,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GLM + H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.022917691438593187,\n        \"min\": 0.0,\n        \"max\": 0.03969460596382968,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"RF\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GBRT + H\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe",
       "variable_name": "output"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-37e0ff77-1e2f-43cf-b64f-06ee95e9e23b\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OLS + H</th>\n",
       "      <th>OLS-3 + H</th>\n",
       "      <th>PCR</th>\n",
       "      <th>PLS</th>\n",
       "      <th>Enet + H</th>\n",
       "      <th>GLM + H</th>\n",
       "      <th>RF</th>\n",
       "      <th>GBRT + H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>0.020132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00831</td>\n",
       "      <td>0.029684</td>\n",
       "      <td>0.040032</td>\n",
       "      <td>0.039695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Top 1000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bottom 1000</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-37e0ff77-1e2f-43cf-b64f-06ee95e9e23b')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-37e0ff77-1e2f-43cf-b64f-06ee95e9e23b button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-37e0ff77-1e2f-43cf-b64f-06ee95e9e23b');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "<div id=\"df-dee65ee9-556e-4d79-b51c-4fdd70fd7a27\">\n",
       "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dee65ee9-556e-4d79-b51c-4fdd70fd7a27')\"\n",
       "            title=\"Suggest charts\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "     width=\"24px\">\n",
       "    <g>\n",
       "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
       "    </g>\n",
       "</svg>\n",
       "  </button>\n",
       "\n",
       "<style>\n",
       "  .colab-df-quickchart {\n",
       "      --bg-color: #E8F0FE;\n",
       "      --fill-color: #1967D2;\n",
       "      --hover-bg-color: #E2EBFA;\n",
       "      --hover-fill-color: #174EA6;\n",
       "      --disabled-fill-color: #AAA;\n",
       "      --disabled-bg-color: #DDD;\n",
       "  }\n",
       "\n",
       "  [theme=dark] .colab-df-quickchart {\n",
       "      --bg-color: #3B4455;\n",
       "      --fill-color: #D2E3FC;\n",
       "      --hover-bg-color: #434B5C;\n",
       "      --hover-fill-color: #FFFFFF;\n",
       "      --disabled-bg-color: #3B4455;\n",
       "      --disabled-fill-color: #666;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart {\n",
       "    background-color: var(--bg-color);\n",
       "    border: none;\n",
       "    border-radius: 50%;\n",
       "    cursor: pointer;\n",
       "    display: none;\n",
       "    fill: var(--fill-color);\n",
       "    height: 32px;\n",
       "    padding: 0;\n",
       "    width: 32px;\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart:hover {\n",
       "    background-color: var(--hover-bg-color);\n",
       "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "    fill: var(--button-hover-fill-color);\n",
       "  }\n",
       "\n",
       "  .colab-df-quickchart-complete:disabled,\n",
       "  .colab-df-quickchart-complete:disabled:hover {\n",
       "    background-color: var(--disabled-bg-color);\n",
       "    fill: var(--disabled-fill-color);\n",
       "    box-shadow: none;\n",
       "  }\n",
       "\n",
       "  .colab-df-spinner {\n",
       "    border: 2px solid var(--fill-color);\n",
       "    border-color: transparent;\n",
       "    border-bottom-color: var(--fill-color);\n",
       "    animation:\n",
       "      spin 1s steps(1) infinite;\n",
       "  }\n",
       "\n",
       "  @keyframes spin {\n",
       "    0% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "      border-left-color: var(--fill-color);\n",
       "    }\n",
       "    20% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    30% {\n",
       "      border-color: transparent;\n",
       "      border-left-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    40% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-top-color: var(--fill-color);\n",
       "    }\n",
       "    60% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "    }\n",
       "    80% {\n",
       "      border-color: transparent;\n",
       "      border-right-color: var(--fill-color);\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "    90% {\n",
       "      border-color: transparent;\n",
       "      border-bottom-color: var(--fill-color);\n",
       "    }\n",
       "  }\n",
       "</style>\n",
       "\n",
       "  <script>\n",
       "    async function quickchart(key) {\n",
       "      const quickchartButtonEl =\n",
       "        document.querySelector('#' + key + ' button');\n",
       "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
       "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
       "      try {\n",
       "        const charts = await google.colab.kernel.invokeFunction(\n",
       "            'suggestCharts', [key], {});\n",
       "      } catch (error) {\n",
       "        console.error('Error during call to suggestCharts:', error);\n",
       "      }\n",
       "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
       "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
       "    }\n",
       "    (() => {\n",
       "      let quickchartButtonEl =\n",
       "        document.querySelector('#df-dee65ee9-556e-4d79-b51c-4fdd70fd7a27 button');\n",
       "      quickchartButtonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "    })();\n",
       "  </script>\n",
       "</div>\n",
       "\n",
       "  <div id=\"id_2370bc6a-8e79-4bd0-9e98-40aa742b01ce\">\n",
       "    <style>\n",
       "      .colab-df-generate {\n",
       "        background-color: #E8F0FE;\n",
       "        border: none;\n",
       "        border-radius: 50%;\n",
       "        cursor: pointer;\n",
       "        display: none;\n",
       "        fill: #1967D2;\n",
       "        height: 32px;\n",
       "        padding: 0 0 0 0;\n",
       "        width: 32px;\n",
       "      }\n",
       "\n",
       "      .colab-df-generate:hover {\n",
       "        background-color: #E2EBFA;\n",
       "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "        fill: #174EA6;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate {\n",
       "        background-color: #3B4455;\n",
       "        fill: #D2E3FC;\n",
       "      }\n",
       "\n",
       "      [theme=dark] .colab-df-generate:hover {\n",
       "        background-color: #434B5C;\n",
       "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "        fill: #FFFFFF;\n",
       "      }\n",
       "    </style>\n",
       "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('output')\"\n",
       "            title=\"Generate code using this dataframe.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "    <script>\n",
       "      (() => {\n",
       "      const buttonEl =\n",
       "        document.querySelector('#id_2370bc6a-8e79-4bd0-9e98-40aa742b01ce button.colab-df-generate');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      buttonEl.onclick = () => {\n",
       "        google.colab.notebook.generateWithVariable('output');\n",
       "      }\n",
       "      })();\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "              OLS + H  OLS-3 + H      PCR       PLS  Enet + H   GLM + H   RF  \\\n",
       "All          0.020132        0.0  0.00831  0.029684  0.040032  0.039695  0.0   \n",
       "Top 1000     0.000000        0.0  0.00000  0.000000  0.000000  0.000000  0.0   \n",
       "Bottom 1000  0.000000        0.0  0.00000  0.000000  0.000000  0.000000  0.0   \n",
       "\n",
       "             GBRT + H  \n",
       "All               0.0  \n",
       "Top 1000          0.0  \n",
       "Bottom 1000       0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fecf48",
   "metadata": {
    "id": "b7fecf48"
   },
   "source": [
    "# Ensemble Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d5ed04f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5d5ed04f",
    "outputId": "87c65eb0-4287-47e6-e15d-a6a214b5a61a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [30:58<00:00, 185.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF R2 : 0.039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MC = 1  # setup MC number\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = os.path.join(path, f'SimuData_p{datanum}/')\n",
    "hh = [1]\n",
    "mo = 1\n",
    "# for hh in [1, 3, 6, 12]:  # correspond to monthly quarterly halfyear and annually returns\n",
    "title = os.path.join(path, f'Simu_p{datanum}/Tree{hh}')\n",
    "\n",
    "if not os.path.isdir(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "\n",
    "titleB = os.path.join(title, 'B')\n",
    "if not os.path.isdir(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "if datanum == 100:\n",
    "    nump = 100\n",
    "N = 200  # Number of CS tickers\n",
    "m = nump * 2  # Number of Characteristics\n",
    "T = 180  # Number of Time Periods\n",
    "\n",
    "per = np.tile(np.arange(1, N + 1), T)\n",
    "time = np.repeat(np.arange(1, T + 1), N)\n",
    "stdv = 0.05\n",
    "theta_w = 0.005\n",
    "\n",
    "# Read Files\n",
    "path1 = f\"{dirstock}c{M}.csv\"\n",
    "path2 = f\"{dirstock}r{mo}_{M}.csv\"\n",
    "c = np.genfromtxt(path1, delimiter=',')\n",
    "r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "# Add Some Elements\n",
    "daylen = np.tile(N, T // 3)\n",
    "daylen_test = daylen\n",
    "ind = np.arange(0, int(N * T / 3))\n",
    "xtrain = c[ind, :]\n",
    "ytrain = r1[ind]\n",
    "trainper = per[ind]\n",
    "ind = np.arange(int(N * T / 3), int(N * (T * 2 / 3 + 1)))\n",
    "xtest = c[ind, :]\n",
    "ytest = r1[ind]\n",
    "testper = per[ind]\n",
    "\n",
    "l1 = c.shape[0]\n",
    "l2 = len(r1)\n",
    "l3 = l2 - np.sum(np.isnan(r1))\n",
    "\n",
    "ind = np.arange(int(N * T * 2 / 3), min(l1, l2, l3))\n",
    "xoos = c[ind, :]\n",
    "yoos = r1[ind]\n",
    "\n",
    "# Monthly Demean\n",
    "ytrain_demean = ytrain - np.mean(ytrain)\n",
    "ytest_demean = ytest - np.mean(ytest)\n",
    "mtrain = np.mean(ytrain)\n",
    "mtest = np.mean(ytest)\n",
    "\n",
    "# Start to train\n",
    "r2_oos = np.zeros(3)  # OOS R2\n",
    "r2_is = np.zeros(3)  # IS R2\n",
    "\n",
    "# Random Forest\n",
    "if nump == 50:\n",
    "    lamv = np.arange(10, 101, 10)\n",
    "elif nump == 100:\n",
    "    lamv = np.arange(10, 201, 20)\n",
    "ne = 100\n",
    "lamc = [2, 4, 8, 16, 32]\n",
    "r = np.zeros((len(lamv), len(lamc), 3))\n",
    "\n",
    "for n1 in tqdm(range(len(lamv))):\n",
    "    nf = lamv[n1]\n",
    "    for n2 in range(len(lamc)):\n",
    "        nn = lamc[n2]\n",
    "        clf = RandomForestRegressor(\n",
    "            n_estimators=ne,\n",
    "            max_features=nf,\n",
    "            max_depth=nn\n",
    "        )\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        yhatbig1 = clf.predict(xtest)\n",
    "        r[n1, n2, 0] = 1 - np.sum(np.power(yhatbig1 - ytest, 2)) / np.sum(\n",
    "        np.power(ytest - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xoos)\n",
    "        r[n1, n2, 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(\n",
    "        np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain)\n",
    "        r[n1, n2, 2] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(\n",
    "        np.power(ytrain - mtrain, 2))\n",
    "\n",
    "fw_2 = np.unravel_index(np.argmax(r[:, :, 0]), r[:, :, 0].shape)\n",
    "r2_oos[0] = r[fw_2[0], fw_2[1], 1]\n",
    "r2_is[0] = r[fw_2[0], fw_2[1], 2]\n",
    "print(f\"RF R2 : {r2_oos[0]:.3f}\")\n",
    "\n",
    "# Save r2_oos and r2_is to files\n",
    "pathr = f\"{title}/roos_{mo}_{M}.csv\"\n",
    "np.savetxt(pathr, r2_oos.reshape(1, -1), delimiter=\",\")\n",
    "pathr = f\"{title}/ris_{mo}_{M}.csv\"\n",
    "np.savetxt(pathr, r2_is.reshape(1, -1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "936e32e5",
   "metadata": {
    "id": "936e32e5"
   },
   "outputs": [],
   "source": [
    "output.iloc[0,6] = r2_oos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816688a4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "816688a4",
    "outputId": "cc464c0b-f6a5-43d2-c51a-555844e36287"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBRT R2 : 0.043\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "mo = 1\n",
    "\n",
    "lamv = np.arange(-1, 0.1, 0.2)\n",
    "r = np.zeros((len(lamv), 50, 3))\n",
    "\n",
    "for n1 in range(len(lamv)):\n",
    "    lr = 10 ** lamv[n1]\n",
    "    alpha = 2\n",
    "    ne = 50\n",
    "    clf = GradientBoostingRegressor(\n",
    "        n_estimators=ne,\n",
    "        learning_rate=lr,\n",
    "        loss='huber',\n",
    "        max_depth=2\n",
    "    )\n",
    "\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    e = clf.staged_predict(xtest)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 0] = np.mean((pred - ytest) ** 2)\n",
    "\n",
    "    e = clf.staged_predict(xoos)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 1] = np.mean((pred - yoos) ** 2)\n",
    "\n",
    "    e = clf.staged_predict(xtrain)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 2] = np.mean((pred - ytrain) ** 2)\n",
    "\n",
    "fw_2 = np.unravel_index(np.argmin(r[:, :, 0]), r[:, :, 0].shape)\n",
    "err1 = np.mean((ytrain - mtrain) ** 2)\n",
    "err2 = np.mean((yoos - mtrain) ** 2)\n",
    "r2_oos[1] = 1 - r[fw_2[0], fw_2[1], 1] / err2\n",
    "r2_is[1] = 1 - r[fw_2[0], fw_2[1], 2] / err1\n",
    "print(f\"GBRT R2 : {r2_oos[1]:.3f}\")\n",
    "\n",
    "# Save r2_oos and r2_is to files\n",
    "pathr = f\"{title}/roos_{mo}_{M}.csv\"\n",
    "np.savetxt(pathr, r2_oos.reshape(1, -1), delimiter=\",\")\n",
    "pathr = f\"{title}/ris_{mo}_{M}.csv\"\n",
    "np.savetxt(pathr, r2_is.reshape(1, -1), delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "uLDzppghGboy",
   "metadata": {
    "id": "uLDzppghGboy"
   },
   "outputs": [],
   "source": [
    "output.iloc[0,7] = r2_oos[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fee7a1",
   "metadata": {
    "id": "80fee7a1"
   },
   "source": [
    "# Additional Manipulations to get top-1000 and bottom-1000 of simulated stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01nu8ibMG6te",
   "metadata": {
    "id": "01nu8ibMG6te"
   },
   "outputs": [],
   "source": [
    "x_c = pd.read_csv(\"./Simu/SimuData_p50/c1.csv\")\n",
    "x_b = pd.read_csv(\"./Simu/SimuData_p50/r1_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f87469a",
   "metadata": {
    "id": "7f87469a"
   },
   "outputs": [],
   "source": [
    "updated = pd.merge(x_c, x_b, left_index=True, right_index=True, how='inner')\n",
    "#assume that the 4th column is the Market Value of the stock. Proceeding to arrange it in accordance to the column values\n",
    "updated = updated.sort_values(by=updated.columns[3], ascending=False)\n",
    "rtop_1 = updated.iloc[:,:1]\n",
    "ctop1 = updated.iloc[:,1:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "89d0bc76",
   "metadata": {
    "id": "89d0bc76"
   },
   "outputs": [],
   "source": [
    "rtop_1.to_csv('./Simu/SimuData_p50/r1_1.csv', index=False, header=False)\n",
    "ctop1.to_csv('./Simu/SimuData_p50/c1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8224cbb",
   "metadata": {
    "id": "b8224cbb"
   },
   "source": [
    "Same simulations for top 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "aa598ba3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aa598ba3",
    "outputId": "a2ce5ef1-c497-4a8a-e102-32bb32a48686"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: -6.674\n",
      "Simple OLS+H R2: -3.348\n",
      "PCR R2: 0.107\n",
      "PLS R2: 0.000\n",
      "Enet R2 : 0.161\n",
      "Enet+H R2 : -0.013\n",
      "Group Lasso R2: -0.273\n",
      "Group Lasso+H R2: 0.099\n"
     ]
    }
   ],
   "source": [
    "MC = 1  # setup MC number\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "# hh = [1, 3, 6, 12]  # correspond to monthly, quarterly, half-year, and annually returns\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 4  # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PCR\n",
    "        modeln += 1\n",
    "        ne = 30\n",
    "        X = np.dot(xtrain.T, xtrain)\n",
    "        pca_vec = V.T\n",
    "        p1 = pca_vec[:, :ne]\n",
    "        Z = np.dot(xtrain, p1)\n",
    "        r = np.zeros((3, ne))\n",
    "        B = np.zeros((xtrain.shape[1], ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne - 1):\n",
    "            xx = Z[:, :j + 1]\n",
    "            b = np.dot(np.linalg.inv(np.dot(xx.T, xx)), np.dot(xx.T, Y))\n",
    "            b = np.dot(p1[:, :j + 1], b)\n",
    "\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytest[:1000], 2)) / np.sum(np.power(ytest[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "            B[:, j] = b\n",
    "\n",
    "        b = np.zeros(xtest.shape[1])\n",
    "        j = ne - 1\n",
    "        yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "        r[0, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytest[:1000], 2)) / np.sum(np.power(ytest[:1000] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r[1, j] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r[2, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "        B[:, j] = b\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PCR R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PLS\n",
    "        modeln += 1\n",
    "        B = pls(xtrain, ytrain_demean, 30)\n",
    "        ne = 30\n",
    "        r = np.zeros((3, ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne):\n",
    "            b = B[:, j]\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytest[:1000], 2)) / np.sum(np.power(ytest[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln - 1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # Elastic Net\n",
    "        modeln += 1\n",
    "        lamv = np.arange(-2, 4.1, 0.1)\n",
    "        alpha = 0.5\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j in range(len(lamv)):\n",
    "            l2 = 10 ** lamv[j]\n",
    "            func = soft_threshode\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytest[:1000], 2)) / np.sum(np.power(ytest[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        l2 = 10 ** lamv[int(fw1(r[0]))]\n",
    "        func = soft_threshode\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshode\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln-1] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln-1] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet+H R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        # Group Lasso\n",
    "        kn = 4\n",
    "        th = np.zeros((kn, xtrain.shape[1]))\n",
    "        th[1, :] = 0\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            th[:, i] = np.quantile(xtrain[:, i], np.arange(kn) / kn)\n",
    "\n",
    "        xtrain = cut_knots_degree2(xtrain, kn, th)\n",
    "        xtest = cut_knots_degree2(xtest, kn, th)\n",
    "        xoos = cut_knots_degree2(xoos, kn, th)\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] = xtrain[:, i] / s\n",
    "                xtest[:, i] = xtest[:, i] / s\n",
    "                xoos[:, i] = xoos[:, i] / s\n",
    "\n",
    "        Y = ytrain_demean\n",
    "        XX = xtrain.T @ xtrain\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        XY = xtrain.T @ Y\n",
    "\n",
    "        modeln += 1\n",
    "        lamv = np.arange(0.5, 3.1, 0.1)\n",
    "        nc = XX.shape[1] // (kn + 1)\n",
    "        groups = np.repeat(np.arange(1, nc + 1), kn + 1)\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j, lam in enumerate(lamv):\n",
    "            l2 = 10 ** lam\n",
    "            func = soft_threshodg\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = xtest @ b + mtrain\n",
    "            r[0, j] = 1 - np.sum((yhatbig1 - ytest) ** 2) / np.sum((ytest - mtrain) ** 2)\n",
    "            yhatbig1 = xoos @ b + mtrain\n",
    "            r[1, j] = 1 - np.sum((yhatbig1 - yoos) ** 2) / np.sum((yoos - mtrain) ** 2)\n",
    "            yhatbig1 = xtrain @ b + mtrain\n",
    "            r[2, j] = 1 - np.sum((yhatbig1 - ytrain) ** 2) / np.sum((ytrain - mtrain) ** 2)\n",
    "\n",
    "        r2_oos[modeln-1] = r[1, np.int16(fw1(r[0, :]))]\n",
    "        r2_is[modeln-1] = r[2, np.int16(fw1(r[0, :]))]\n",
    "        l2 = 10 ** lamv[np.int16(fw1(r[0, :]))]\n",
    "\n",
    "        func = soft_threshodg\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso R2:\", np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshodg\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = xoos @ b + mtrain\n",
    "        r2_oos[modeln-1] = 1 - np.sum((yhatbig1[:1000] - yoos[:1000]) ** 2) / np.sum((yoos[:1000] - mtrain) ** 2)\n",
    "        yhatbig1 = xtrain @ b + mtrain\n",
    "        r2_is[modeln-1] = 1 - np.sum((yhatbig1[:1000] - ytrain[:1000]) ** 2) / np.sum((ytrain[:1000] - mtrain) ** 2)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso+H R2:\", np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        pathr = f\"{title}/roos\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_oos, delimiter=\",\")\n",
    "\n",
    "        pathr = f\"{title}/ris\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_is, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "afec222c",
   "metadata": {
    "id": "afec222c"
   },
   "outputs": [],
   "source": [
    "output.iloc[1,0] =r2_oos[1]\n",
    "output.iloc[1,2] = r2_oos[2]\n",
    "output.iloc[1,3] = r2_oos[3]\n",
    "output.iloc[1,4] = r2_oos[5]\n",
    "output.iloc[1,5] = r2_oos[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a32dc",
   "metadata": {
    "id": "649a32dc"
   },
   "source": [
    "And for the bottom 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b3cdeb36",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b3cdeb36",
    "outputId": "96484e56-9045-4b3c-8b35-6331d12c9968"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: -6.674\n",
      "Simple OLS+H R2: -7.659\n",
      "PCR R2: -0.204\n",
      "PLS R2: 0.000\n",
      "Enet R2 : -0.157\n",
      "Enet+H R2 : 0.036\n",
      "Group Lasso R2: -0.273\n",
      "Group Lasso+H R2: -0.121\n"
     ]
    }
   ],
   "source": [
    "MC = 1  # setup MC number\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "# hh = [1, 3, 6, 12]  # correspond to monthly, quarterly, half-year, and annually returns\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 4  # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln -1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:]- mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:]- mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PCR\n",
    "        modeln += 1\n",
    "        ne = 30\n",
    "        X = np.dot(xtrain.T, xtrain)\n",
    "        pca_vec = V.T\n",
    "        p1 = pca_vec[:, :ne]\n",
    "        Z = np.dot(xtrain, p1)\n",
    "        r = np.zeros((3, ne))\n",
    "        B = np.zeros((xtrain.shape[1], ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne - 1):\n",
    "            xx = Z[:, :j + 1]\n",
    "            b = np.dot(np.linalg.inv(np.dot(xx.T, xx)), np.dot(xx.T, Y))\n",
    "            b = np.dot(p1[:, :j + 1], b)\n",
    "\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytest[-1000:], 2)) / np.sum(np.power(ytest[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "            B[:, j] = b\n",
    "\n",
    "        b = np.zeros(xtest.shape[1])\n",
    "        j = ne - 1\n",
    "        yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "        r[0, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytest[-1000:], 2)) / np.sum(np.power(ytest[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r[1, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r[2, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "        B[:, j] = b\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PCR R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # PLS\n",
    "        modeln += 1\n",
    "        B = pls(xtrain, ytrain_demean, 30)\n",
    "        ne = 30\n",
    "        r = np.zeros((3, ne))\n",
    "        Y = ytrain_demean\n",
    "\n",
    "        for j in range(ne):\n",
    "            b = B[:, j]\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytest[-1000:], 2)) / np.sum(np.power(ytest[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        b = B[:, fw1(r[0, :].tolist())]\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"PLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # Elastic Net\n",
    "        modeln += 1\n",
    "        lamv = np.arange(-2, 4.1, 0.1)\n",
    "        alpha = 0.5\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j in range(len(lamv)):\n",
    "            l2 = 10 ** lamv[j]\n",
    "            func = soft_threshode\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = np.dot(xtest, b) + mtrain\n",
    "            r[0, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytest[-1000:], 2)) / np.sum(np.power(ytest[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "            r[1, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "            yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "            r[2, j] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "\n",
    "        r2_oos[modeln - 1] = r[1, fw1(r[0, :].tolist())]\n",
    "        r2_is[modeln - 1] = r[2, fw1(r[0, :].tolist())]\n",
    "        l2 = 10 ** lamv[int(fw1(r[0]))]\n",
    "        func = soft_threshode\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshode\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln-1] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln-1] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=',')\n",
    "        print('Enet+H R2 :', np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        # Group Lasso\n",
    "        kn = 4\n",
    "        th = np.zeros((kn, xtrain.shape[1]))\n",
    "        th[1, :] = 0\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            th[:, i] = np.quantile(xtrain[:, i], np.arange(kn) / kn)\n",
    "\n",
    "        xtrain = cut_knots_degree2(xtrain, kn, th)\n",
    "        xtest = cut_knots_degree2(xtest, kn, th)\n",
    "        xoos = cut_knots_degree2(xoos, kn, th)\n",
    "\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] = xtrain[:, i] / s\n",
    "                xtest[:, i] = xtest[:, i] / s\n",
    "                xoos[:, i] = xoos[:, i] / s\n",
    "\n",
    "        Y = ytrain_demean\n",
    "        XX = xtrain.T @ xtrain\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        XY = xtrain.T @ Y\n",
    "\n",
    "        modeln += 1\n",
    "        lamv = np.arange(0.5, 3.1, 0.1)\n",
    "        nc = XX.shape[1] // (kn + 1)\n",
    "        groups = np.repeat(np.arange(1, nc + 1), kn + 1)\n",
    "        r = np.zeros((3, len(lamv)))\n",
    "\n",
    "        for j, lam in enumerate(lamv):\n",
    "            l2 = 10 ** lam\n",
    "            func = soft_threshodg\n",
    "            b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "            yhatbig1 = xtest @ b + mtrain\n",
    "            r[0, j] = 1 - np.sum((yhatbig1 - ytest) ** 2) / np.sum((ytest - mtrain) ** 2)\n",
    "            yhatbig1 = xoos @ b + mtrain\n",
    "            r[1, j] = 1 - np.sum((yhatbig1 - yoos) ** 2) / np.sum((yoos - mtrain) ** 2)\n",
    "            yhatbig1 = xtrain @ b + mtrain\n",
    "            r[2, j] = 1 - np.sum((yhatbig1 - ytrain) ** 2) / np.sum((ytrain - mtrain) ** 2)\n",
    "\n",
    "        r2_oos[modeln-1] = r[1, np.int16(fw1(r[0, :]))]\n",
    "        r2_is[modeln-1] = r[2, np.int16(fw1(r[0, :]))]\n",
    "        l2 = 10 ** lamv[np.int16(fw1(r[0, :]))]\n",
    "\n",
    "        func = soft_threshodg\n",
    "        b = proximal(groups, nc, XX, XY, tol, L, l2, func)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso R2:\", np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        modeln += 1\n",
    "        func = soft_threshodg\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, l2, func)\n",
    "        yhatbig1 = xoos @ b + mtrain\n",
    "        r2_oos[modeln-1] = 1 - np.sum((yhatbig1[-1000:] - yoos[-1000:]) ** 2) / np.sum((yoos[-1000:] - mtrain) ** 2)\n",
    "        yhatbig1 = xtrain @ b + mtrain\n",
    "        r2_is[modeln-1] = 1 - np.sum((yhatbig1[-1000:] - ytrain[-1000:]) ** 2) / np.sum((ytrain[-1000:] - mtrain) ** 2)\n",
    "        pathb = f\"{title}/B/b\"\n",
    "        pathb = f\"{pathb}_{mo}_{M}_{modeln-1}.csv\"\n",
    "        np.savetxt(pathb, b, delimiter=\",\")\n",
    "\n",
    "        print(\"Group Lasso+H R2:\", np.round(r2_oos[modeln-1], 3))\n",
    "\n",
    "        pathr = f\"{title}/roos\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_oos, delimiter=\",\")\n",
    "\n",
    "        pathr = f\"{title}/ris\"\n",
    "        pathr = f\"{pathr}_{mo}_{M}.csv\"\n",
    "        np.savetxt(pathr, r2_is, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35fe1b5e",
   "metadata": {
    "id": "35fe1b5e"
   },
   "outputs": [],
   "source": [
    "output.iloc[2,0] =r2_oos[1]\n",
    "output.iloc[2,2] = r2_oos[2]\n",
    "output.iloc[2,3] = r2_oos[3]\n",
    "output.iloc[2,4] = r2_oos[5]\n",
    "output.iloc[2,5] = r2_oos[7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4945af58",
   "metadata": {
    "id": "4945af58"
   },
   "source": [
    "Now moving to boosing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ade397fa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ade397fa",
    "outputId": "c472e26b-4d92-4268-c137-0643ad6cb87f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [29:30<00:00, 177.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF R2 for first 1000 : -0.577, RF R2 for last 1000 : 0.011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MC = 1  # setup MC number\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = os.path.join(path, f'SimuData_p{datanum}/')\n",
    "hh = [1]\n",
    "mo = 1\n",
    "# for hh in [1, 3, 6, 12]:  # correspond to monthly quarterly halfyear and annually returns\n",
    "title = os.path.join(path, f'Simu_p{datanum}/Tree{hh}')\n",
    "\n",
    "if not os.path.isdir(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "\n",
    "titleB = os.path.join(title, 'B')\n",
    "if not os.path.isdir(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "if datanum == 100:\n",
    "    nump = 100\n",
    "N = 200  # Number of CS tickers\n",
    "m = nump * 2  # Number of Characteristics\n",
    "T = 180  # Number of Time Periods\n",
    "\n",
    "per = np.tile(np.arange(1, N + 1), T)\n",
    "time = np.repeat(np.arange(1, T + 1), N)\n",
    "stdv = 0.05\n",
    "theta_w = 0.005\n",
    "\n",
    "# Read Files\n",
    "path1 = f\"{dirstock}c{M}.csv\"\n",
    "path2 = f\"{dirstock}r{mo}_{M}.csv\"\n",
    "c = np.genfromtxt(path1, delimiter=',')\n",
    "r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "# Add Some Elements\n",
    "daylen = np.tile(N, T // 3)\n",
    "daylen_test = daylen\n",
    "ind = np.arange(0, int(N * T / 3))\n",
    "xtrain = c[ind, :]\n",
    "ytrain = r1[ind]\n",
    "trainper = per[ind]\n",
    "ind = np.arange(int(N * T / 3), int(N * (T * 2 / 3 + 1)))\n",
    "xtest = c[ind, :]\n",
    "ytest = r1[ind]\n",
    "testper = per[ind]\n",
    "\n",
    "l1 = c.shape[0]\n",
    "l2 = len(r1)\n",
    "l3 = l2 - np.sum(np.isnan(r1))\n",
    "\n",
    "ind = np.arange(int(N * T * 2 / 3), min(l1, l2, l3))\n",
    "xoos = c[ind, :]\n",
    "yoos = r1[ind]\n",
    "\n",
    "# Monthly Demean\n",
    "ytrain_demean = ytrain - np.mean(ytrain)\n",
    "ytest_demean = ytest - np.mean(ytest)\n",
    "mtrain = np.mean(ytrain)\n",
    "mtest = np.mean(ytest)\n",
    "\n",
    "# Start to train\n",
    "r2_oos = np.zeros(3)  # OOS R2\n",
    "r2_is = np.zeros(3)\n",
    "r3_oos = np.zeros(3) # IS R2\n",
    "\n",
    "# Random Forest\n",
    "if nump == 50:\n",
    "    lamv = np.arange(10, 101, 10)\n",
    "elif nump == 100:\n",
    "    lamv = np.arange(10, 201, 20)\n",
    "ne = 100\n",
    "lamc = [2, 4, 8, 16, 32]\n",
    "r = np.zeros((len(lamv), len(lamc), 3))\n",
    "rrr = np.zeros((len(lamv), len(lamc), 3))\n",
    "\n",
    "for n1 in tqdm(range(len(lamv))):\n",
    "    nf = lamv[n1]\n",
    "    for n2 in range(len(lamc)):\n",
    "        nn = lamc[n2]\n",
    "        clf = RandomForestRegressor(\n",
    "            n_estimators=ne,\n",
    "            max_features=nf,\n",
    "            max_depth=nn\n",
    "        )\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        yhatbig1 = clf.predict(xtest)\n",
    "\n",
    "        r[n1, n2, 0] = 1 - np.sum(np.power(yhatbig1[:1000] - ytest[:1000], 2)) / np.sum(\n",
    "        np.power(ytest[:1000] - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xoos)\n",
    "        r[n1, n2, 1] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(\n",
    "        np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain)\n",
    "        r[n1, n2, 2] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(\n",
    "        np.power(ytrain[:1000] - mtrain, 2))\n",
    "\n",
    "        rrr[n1, n2, 0] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytest[-1000:], 2)) / np.sum(\n",
    "        np.power(ytest[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xoos)\n",
    "        rrr[n1, n2, 1] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(\n",
    "        np.power(yoos[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain)\n",
    "        rrr[n1, n2, 2] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(\n",
    "        np.power(ytrain[-1000:] - mtrain, 2))\n",
    "\n",
    "fw_2 = np.unravel_index(np.argmax(r[:, :, 0]), r[:, :, 0].shape)\n",
    "fw_3 = np.unravel_index(np.argmax(rrr[:, :, 0]), rrr[:, :, 0].shape)\n",
    "\n",
    "r2_oos[0] = r[fw_2[0], fw_2[1], 1]\n",
    "r3_oos[0] = r[fw_3[0], fw_3[1], 1]\n",
    "print(f\"RF R2 for first 1000 : {r2_oos[0]:.3f}, RF R2 for last 1000 : {r3_oos[0]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "22cbdff8",
   "metadata": {
    "id": "22cbdff8"
   },
   "outputs": [],
   "source": [
    "output.iloc[1,6] =r2_oos[0]\n",
    "output.iloc[2,6] =r3_oos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9ea56b01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9ea56b01",
    "outputId": "eb4b62a8-3a7b-4042-b0e7-d5f0f3515037"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBRT R2 for the first 1000 : 0.019, GBRT R2 for last 1000 : 0.013\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "mo = 1\n",
    "\n",
    "lamv = np.arange(-1, 0.1, 0.2)\n",
    "r = np.zeros((len(lamv), 50, 3))\n",
    "rrr = np.zeros((len(lamv), 50, 3))\n",
    "\n",
    "for n1 in range(len(lamv)):\n",
    "    lr = 10 ** lamv[n1]\n",
    "    alpha = 2\n",
    "    ne = 50\n",
    "    clf = GradientBoostingRegressor(\n",
    "        n_estimators=ne,\n",
    "        learning_rate=lr,\n",
    "        loss='huber',\n",
    "        max_depth=2\n",
    "    )\n",
    "\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    e = clf.staged_predict(xtest)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 0] = np.mean((pred - ytest) ** 2)\n",
    "\n",
    "    e = clf.staged_predict(xoos)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 1] = np.mean((pred - yoos) ** 2)\n",
    "\n",
    "    e = clf.staged_predict(xtrain)\n",
    "    for i, pred in enumerate(e):\n",
    "        r[n1, i, 2] = np.mean((pred[:1000] - ytrain[:1000]) ** 2)\n",
    "        rrr[n1, i, 2] = np.mean((pred[-1000:] - ytrain[-1000:]) ** 2)\n",
    "\n",
    "\n",
    "fw_2 = np.unravel_index(np.argmin(r[:, :, 0]), r[:, :, 0].shape)\n",
    "fw_3 = np.unravel_index(np.argmin(rrr[:, :, 0]), rrr[:, :, 0].shape)\n",
    "err2 = np.mean((yoos[:1000] - mtrain) ** 2)\n",
    "err3 = np.mean((yoos[-1000:] - mtrain) ** 2)\n",
    "r2_oos[1] = 1 - r[fw_2[0], fw_2[1], 1] / err2\n",
    "r3_oos[1] = 1 - r[fw_3[0], fw_3[1], 1] / err3\n",
    "print(f\"GBRT R2 for the first 1000 : {r2_oos[1]:.3f}, GBRT R2 for last 1000 : {r3_oos[1]:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "cba824ed",
   "metadata": {
    "id": "cba824ed"
   },
   "outputs": [],
   "source": [
    "output.iloc[1,7] =r2_oos[1]\n",
    "output.iloc[2,7] =r3_oos[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92594d5",
   "metadata": {
    "id": "d92594d5"
   },
   "source": [
    "Special Case: OLS-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d13fbf45",
   "metadata": {
    "id": "d13fbf45"
   },
   "outputs": [],
   "source": [
    "updated = merged_dataset = pd.merge(x_c, x_b, left_index=True, right_index=True, how='inner')\n",
    "#assume that the 4th column is the Market Value of the stock. Proceeding to arrange it in accordance to the column values\n",
    "updated = updated.sort_values(by=updated.columns[3], ascending=False)\n",
    "rtop_1 = updated.iloc[:,:1]\n",
    "ctop1 = updated.iloc[:,1:4]\n",
    "\n",
    "rtop_1.to_csv('./Simu/SimuData_p50/r1_1.csv', index=False, header=False)\n",
    "ctop1.to_csv('./Simu/SimuData_p50/c1.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0069b908",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0069b908",
    "outputId": "716432ca-2025-4f7c-dc1d-726b196a85e6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: -0.006\n",
      "Simple OLS+H R2: -0.010\n"
     ]
    }
   ],
   "source": [
    "MC = 1\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 180   # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bb42aefb",
   "metadata": {
    "id": "bb42aefb"
   },
   "outputs": [],
   "source": [
    "output.iloc[0,1] = r2_oos[modeln - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "24586276",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "24586276",
    "outputId": "b912955d-23d8-4aeb-a4ad-3f7afe652ea2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: -0.001\n",
      "Simple OLS+H R2: -0.003\n"
     ]
    }
   ],
   "source": [
    "MC = 1\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 180   # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - yoos[:1000], 2)) / np.sum(np.power(yoos[:1000] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1[:1000] - ytrain[:1000], 2)) / np.sum(np.power(ytrain[:1000] - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1221f97c",
   "metadata": {
    "id": "1221f97c"
   },
   "outputs": [],
   "source": [
    "output.iloc[1,1] = r2_oos[modeln - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d5f80a2b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d5f80a2b",
    "outputId": "48240730-1487-4861-cfc3-dfe4b513dbf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### MCMC : 1, Model : 1 ###\n",
      "Simple OLS R2: -0.006\n",
      "Simple OLS+H R2: 0.010\n"
     ]
    }
   ],
   "source": [
    "MC = 1\n",
    "datanum = 50  # Or datanum = 100; separately run two cases\n",
    "path = './Simu'  # set your own folder path\n",
    "dirstock = f\"{path}/SimuData_p{datanum}/\"\n",
    "\n",
    "hh = [1]\n",
    "title = f\"{path}/Simu_p{datanum}/Reg{hh[0]}\"\n",
    "if not os.path.exists(title) and MC == 1:\n",
    "    os.makedirs(title)\n",
    "titleB = f\"{title}/B\"\n",
    "if not os.path.exists(titleB) and MC == 1:\n",
    "    os.makedirs(titleB)\n",
    "if datanum == 50:\n",
    "    nump = 50\n",
    "elif datanum == 100:\n",
    "    nump = 100\n",
    "mu = 0.2 * np.sqrt(hh[0])\n",
    "tol = 10**(-10)\n",
    "\n",
    "for M in range(1, 2):  # Assuming range for M\n",
    "    for mo in range(1, 2):  # Assuming range for mo\n",
    "\n",
    "        print('### MCMC : {}, Model : {} ###'.format(M, mo))\n",
    "\n",
    "        N = 200   # Number of CS tickers\n",
    "        m = nump * 2   # Number of Characteristics\n",
    "        T = 180   # Number of Time Periods\n",
    "\n",
    "        per = np.tile(np.arange(1, N+1), T)\n",
    "        time = np.repeat(np.arange(1, T+1), N)\n",
    "        stdv = 0.05\n",
    "        theta_w = 0.005\n",
    "\n",
    "        # Read Files\n",
    "        path1 = dirstock + 'c' + str(M) + '.csv'\n",
    "        path2 = dirstock + 'r' + str(mo) + '_' + str(M) + '.csv'\n",
    "        c = np.genfromtxt(path1, delimiter=',')\n",
    "        r1 = np.genfromtxt(path2, delimiter=',')\n",
    "\n",
    "        # Add Some Elements\n",
    "        daylen = np.repeat(N, T//3)\n",
    "        daylen_test = daylen.copy()\n",
    "        ind = np.arange(0, N*T//3)\n",
    "        xtrain = c[ind]\n",
    "        ytrain = r1[ind]\n",
    "        trainper = per[ind]\n",
    "        start_idx = math.floor(N * T / 3) + 1\n",
    "        end_idx = math.floor(N * (T * 2 / 3 - hh[0] + 1))\n",
    "        ind = list(range(start_idx, end_idx))\n",
    "        xtest = c[ind]\n",
    "        ytest = r1[ind]\n",
    "        testper = per[ind]\n",
    "\n",
    "        l1 = c.shape[0]\n",
    "        l2 = len(r1)\n",
    "        l3 = l2 - np.isnan(r1).sum()\n",
    "\n",
    "        ind = np.arange(N*(2*T//3), min([l1, l2, l3]))\n",
    "        xoos = c[ind]\n",
    "        yoos = r1[ind]\n",
    "\n",
    "        # Monthly Demean\n",
    "        ytrain_demean = ytrain - np.mean(ytrain)\n",
    "        ytest_demean = ytest - np.mean(ytest)\n",
    "        mtrain = np.mean(ytrain)\n",
    "        mtest = np.mean(ytest)\n",
    "\n",
    "        # Calculate Sufficient Stats\n",
    "        sd = np.zeros(xtrain.shape[1])\n",
    "        for i in range(xtrain.shape[1]):\n",
    "            s = np.std(xtrain[:, i])\n",
    "            if s > 0:\n",
    "                xtrain[:, i] /= s\n",
    "                xtest[:, i] /= s\n",
    "                xoos[:, i] /= s\n",
    "                sd[i] = s\n",
    "\n",
    "        XX = np.dot(xtrain.T, xtrain)\n",
    "        U, S, V = np.linalg.svd(XX)\n",
    "        L = S[0]\n",
    "        Y = ytrain_demean\n",
    "        XY = np.dot(xtrain.T, Y)\n",
    "\n",
    "\n",
    "        #OLS\n",
    "\n",
    "        # Initialize arrays\n",
    "        r2_oos = np.zeros(13)\n",
    "        r2_is = np.zeros(13)\n",
    "        modeln = 0\n",
    "        groups = 0\n",
    "        nc = 0\n",
    "\n",
    "        # OLS\n",
    "        modeln += 1\n",
    "        clf = LinearRegression(fit_intercept=False)\n",
    "        clf.fit(xtrain, ytrain_demean)\n",
    "        yhatbig1 = clf.predict(xoos) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - yoos, 2)) / np.sum(np.power(yoos - mtrain, 2))\n",
    "        yhatbig1 = clf.predict(xtrain) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1 - ytrain, 2)) / np.sum(np.power(ytrain - mtrain, 2))\n",
    "        b = clf.coef_\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS R2: {r2_oos[modeln - 1]:.3f}\")\n",
    "\n",
    "        # OLS+H\n",
    "        modeln += 1\n",
    "        func = soft_threshodl\n",
    "        b = proximalH(groups, nc, xtest, mtrain, ytest, b, xtrain, ytrain_demean, mu, tol, L, 0, func)\n",
    "        yhatbig1 = np.dot(xoos, b) + mtrain\n",
    "        r2_oos[modeln - 1] = 1 - np.sum(np.power(yhatbig1[-1000:] - yoos[-1000:], 2)) / np.sum(np.power(yoos[-1000:] - mtrain, 2))\n",
    "        yhatbig1 = np.dot(xtrain, b) + mtrain\n",
    "        r2_is[modeln - 1] = 1 - np.sum(np.power(yhatbig1[-1000:] - ytrain[-1000:], 2)) / np.sum(np.power(ytrain[-1000:] - mtrain, 2))\n",
    "        pathb = f\"{title}/B/b{mo}_{M}_{modeln}.csv\"\n",
    "        pd.DataFrame(b).to_csv(pathb, index=False, header=False)\n",
    "        print(f\"Simple OLS+H R2: {r2_oos[modeln - 1]:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c906e204",
   "metadata": {
    "id": "c906e204"
   },
   "outputs": [],
   "source": [
    "output.iloc[2,1] = r2_oos[modeln - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "64db4173",
   "metadata": {
    "collapsed": true,
    "id": "64db4173"
   },
   "outputs": [],
   "source": [
    "output.to_excel(\"resulting_oos.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
